PRD: ML Pipeline for Kt/V and PET Prediction in Peritoneal Dialysis (DETECT-PD)
Background & Objective
The DETECT-PD study (Dialysis Efficiency and Transporter Evaluation Computational Tool in Peritoneal Dialysis) is a prospective investigation aiming to leverage AI for predicting dialysis adequacy and peritoneal membrane transport status[1][2]. In peritoneal dialysis (PD), two key measures guide patient management:
•	Kt/V – a laboratory-derived number indicating how well PD is removing waste (urea) from the body[3]. In clinical practice, Kt/V ≥ 1.7 is often considered an adequate PD dose[4].
•	Peritoneal Equilibration Test (PET) – a 4-hour test measuring how quickly solutes (like creatinine) equilibrate between blood and dialysate[5]. PET categorizes the peritoneal membrane as high, average, or low transporter based on the dialysate/plasma creatinine ratio[6].
Objective: Build a machine learning pipeline to predict continuous Kt/V and PET values for PD patients using baseline data (demographics, comorbidities, treatment timeline, and lab results). The pipeline will be implemented with ZenML (for pipeline orchestration) and MLflow (for experiment tracking), ensuring all steps, parameters, and metrics are logged for reproducibility and analysis. Ultimately, this model could help identify patients at risk of inadequate dialysis or suboptimal membrane transport early, without requiring immediate lab tests or PET procedures.
Data Ingestion & Splitting
Data Source: The primary dataset is an Excel-based Case Report Form (CRF) capturing patient information from DETECT-PD. It includes: - Demographics: Age, gender, height, weight. - Comorbidities: Indicators for conditions contributing to the Charlson Comorbidity Index (e.g. myocardial infarction, heart failure, diabetes, malignancy, etc.). - Cause of ESRD: Classification of the underlying cause of kidney failure. - PD Treatment Timeline: Dates for key events – Date of eGFR < 10 (the date when kidney function fell below an eGFR of 10 mL/min, signaling end-stage renal failure), Date of PD start (initiation of peritoneal dialysis), Date of TKI (Tenckhoff catheter insertion date), and Date of Ax (assessment date, when PET and Kt/V were measured). - PD Prescription Details: Modality (e.g. CAPD vs APD), dialysate regimen (e.g. volumes and dextrose/Icodextrin concentrations), dwell times (inflow/outflow schedules), and volumes. - Biochemical Results: Dialysate (effluent) measurements (urea, creatinine, protein, glucose) and corresponding blood measurements (BUN, creatinine, albumin, etc.). - Outcomes (Ground Truth): PET result (dialysate/plasma creatinine ratio) and Kt/V at the assessment date.
Ingestion Requirements: - Use a ZenML ingestion step to load the Excel data (e.g. via Pandas). The step should parse the necessary columns from the CRF and create a clean DataFrame for downstream processing. - Data Cleaning: Remove or impute missing values as appropriate. For this initial implementation, rows with critical missing fields (e.g. missing outcome or key features) will be dropped to ensure a complete case analysis. Basic data validation (e.g. date fields in proper chronology, numerical ranges plausible) should be performed and any outliers or data errors flagged.
Dataset Split: - Randomly split the cleaned dataset into training (80%) and testing (20%) subsets. Splitting will use a fixed random seed for reproducibility. - The test set must remain untouched during model training and feature selection. It will only be used in the final evaluation step to assess real-world performance. - The split logic will be encapsulated in a ZenML step (e.g. split_data), and the indices or IDs of test patients should be stored to ensure no data leakage. The split ratio (80/20) and random seed should be configurable via pipeline configuration.
Data Preprocessing
Preprocessing prepares raw features for modeling and creates clinically relevant derived features:
•	Charlson Comorbidity Index (CCI): Compute the CCI score for each patient based on comorbidities. The CCI assigns 1–6 points per condition (e.g. 1 point for mild liver disease or prior MI; 2 points for “renal disease” which all patients have by virtue of ESRD; up to 6 points for severe conditions like metastatic cancer or AIDS)[7][8]. Since all patients have end-stage renal disease on dialysis, include the renal disease score (2 points) for everyone. Sum all applicable comorbidity weights (plus any age index if using age in CCI calculation) to get each patient’s CCI[9][10]. This single numeric feature captures overall comorbidity burden, which may impact dialysis adequacy.
•	Time-Based Features: Derive key time intervals (in days) to characterize the patient’s journey to and on PD. These features will be calculated from the date fields:
•	Failure Period: Time from advanced kidney failure to dialysis start. Computed as (PD start date) – (Date eGFR < 10), representing the lag between reaching eGFR <10 and initiating PD. A longer failure period might indicate delayed dialysis initiation.
•	Waiting Period: Time from PD catheter insertion to PD start. Computed as (PD start date) – (Date of TKI). (“TKI” is the Tenckhoff catheter insertion date; PD typically begins ~2–3 weeks after catheter placement.)
•	PD Period: Time on PD therapy before outcome measurement. Computed as (Date of Ax) – (PD start date). The “Ax” assessment date is when PET and Kt/V were measured; this period is roughly the patient’s PD vintage in the study before obtaining outcomes.
These derived features are summarized below:
Feature	Definition
Failure Period	Days from eGFR dropping <10 to PD start (PD start − eGFR<10 date)
Waiting Period	Days from Tenckhoff catheter insertion to PD start (PD start − TKI date)
PD Period	Days on PD until assessment (Ax date − PD start date)
•	Scaling and Transformation: Evaluate distributions of continuous variables (e.g. age, body size, lab results, time intervals). If features are highly skewed, apply log transformation or another normalization to reduce skewness (for example, skewed biochemical markers might be log-transformed to achieve a more Gaussian distribution). All numeric features will be scaled (using standardization or min-max scaling) to ensure the models treat features uniformly. The scaling approach (and any transformation) should be decided based on the training data distribution:
•	If most variables are roughly normal, use StandardScaler (z-score normalization).
•	If some variables have extreme ranges or skew, consider MinMaxScaler or log scaling accordingly.
•	Categorical variables (e.g. PD modality, cause of ESRD categories) will be one-hot encoded or label-encoded as needed.
•	Artifact Saving: The preprocessing step should save fitted transformers (e.g. the scaler object, any encoders) so that they can be consistently applied to new data. These artifacts will be saved in a serialized format (e.g. .h5, .pkl, or joblib file) and versioned. Storing these ensures that during inference or model serving, incoming patient data undergoes the exact same transformations as the training data.
All preprocessing operations will be implemented in a ZenML preprocessing step. This step takes raw training data and outputs the transformed feature set, along with the saved preprocessing artifacts. The step will log any parameters (e.g. chosen scaling method, transformation details) and sample metrics (like feature means/variances) to MLflow for traceability.
Feature Engineering & Selection
The pipeline includes a dedicated feature engineering step to identify the most predictive features:
•	LASSO Feature Selection: We will apply a LASSO-regularized regression approach (L1 regularization) to the training data to perform feature selection. Specifically, a logistic regression model with L1 penalty will be fit to predict an outcome of interest, using all candidate features. The sparsity induced by L1 will force less predictive features’ coefficients to zero, thereby selecting a subset of features with non-zero coefficients. We may formulate this in two ways:
•	Binary Adequacy Classification: For feature selection purposes, define a binary target such as “low Kt/V” (e.g., Kt/V < 1.7 vs ≥1.7)[4] or “high transporter” vs others for PET. Fit a LASSO logistic regression to each classification target to see which features strongly influence the odds. This helps identify important predictors for each aspect of adequacy.
•	Continuous Outcome Regression: Alternatively, use LASSO on a linear regression for Kt/V and PET values directly. However, logistic may be more interpretable for feature picking if focusing on thresholds.
•	Most Predictive Features: From the LASSO model, extract the features with non-zero coefficients as the selected features. These represent the most predictive variables for dialysis adequacy and membrane transport in our data. For transparency, the pipeline can log the selected feature list and their coefficients. (For example, LASSO might reveal that age, diabetes status, dialysate dextrose concentration, and PD period are key predictors, while other features drop out.)
•	Dimensionality Reduction (if needed): If the feature space is still high-dimensional or multicollinear, consider additional techniques such as PCA. However, priority is given to interpretability, so we prefer explicit feature selection (LASSO or manual selection informed by clinical knowledge) over latent factors.
This step ensures we reduce noise and input the most informative features into the final models. The ZenML feature_engineering step will output a refined training dataset (and corresponding test set with the same feature subset), ready for modeling. All decisions (e.g. LASSO regularization strength hyperparameter α) should be configurable, and the chosen value logged to MLflow along with the resulting feature list.
Model Training
Multiple regression models will be trained to predict continuous PET and Kt/V outcomes. This component encompasses model development, selection, and logging:
•	Model Options: We will train at least two different regression algorithms:
•	Extreme Gradient Boosting (XGBoost) – a powerful gradient-boosted tree model known for handling non-linear relationships and feature interactions.
•	Random Forest Regression – an ensemble of decision trees which often performs well with tabular data and can estimate feature importance.
•	(Optionally, other models like linear regression, elastic net, or neural networks could be included for comparison, but XGBoost/RF are primary examples.)
•	Training Process: For each model:
•	Use the preprocessed training set (with features selected from the previous step).
•	Train two separate regressors: one for Kt/V and one for PET. (Alternatively, a multi-output model could predict both simultaneously, but for simplicity, separate models ensure focus on each target.)
•	Perform internal validation on the training data (e.g. cross-validation or a hold-out validation split from the training set) for hyperparameter tuning. Each model’s hyperparameters (like number of trees, max depth for Random Forest, or learning rate for XGBoost) should be configurable via a config file or pipeline parameters.
•	Use early stopping or cross-validated evaluation to prevent overfitting. For example, XGBoost can use a portion of data for early stopping rounds.
•	Metrics Logged during Training: For each model and each target, record the in-training performance metrics (like cross-validated mean squared error, etc.) and any selected hyperparameters. MLflow’s autologging or manual logging will capture these. Key parameters (e.g. tree count, regularization settings) are logged via mlflow.log_param, and intermediate training metrics via mlflow.log_metric.
•	Model Artifacts: After training, save the model objects (e.g. the fitted XGBRegressor and RandomForestRegressor instances) to files (such as .joblib or XGBoost’s native format). These artifacts are output from the ZenML training step and are also logged to MLflow as artifacts. If multiple models are trained, the pipeline can either:
•	Save each model separately (with clear naming, e.g. model_xgb_ktv.pkl, model_rf_pet.pkl), or
•	Register them in MLflow’s model registry for version control (if MLflow tracking server is available).
•	Model Selection: Based on validation results, one model may emerge as best for each target (for instance, XGBoost might yield the highest R² for Kt/V, while Random Forest might be better for PET). The PRD expects both models to be logged; we can decide later which to deploy. The pipeline can include logic to pick the champion model (e.g. highest R² on validation) and tag it accordingly in MLflow.
This training component in ZenML will likely be broken into sub-steps (one per model type or one per target) for clarity, but all training happens on the training split only. By modularizing, we could easily add more models or swap algorithms in the future.
Model Evaluation
Once models are trained, the evaluation step uses the held-out test set (20% of data never seen before) to produce an unbiased assessment of model performance on both PET and Kt/V predictions. This step will output evaluation metrics and diagnostic plots, and log them to MLflow:
•	Performance Metrics: We will compute standard regression metrics:
•	Mean Absolute Error (MAE): average absolute difference between predicted and actual values.
•	Mean Squared Error (MSE): average of squared differences (more penalizing large errors).
•	R² (Coefficient of Determination): proportion of variance in the outcome explained by the model – a primary measure of predictive discrimination (with 1.0 being perfect and 0 meaning no better than mean prediction).
•	Intraclass Correlation Coefficient (ICC): to assess agreement between predictions and true values. ICC treats each patient’s predicted vs actual as a pair and evaluates how well these two measurements concur across patients (an ICC close to 1 indicates the model’s predictions have excellent agreement with the ground truth)[11]. This is a reliability metric often used in medical studies for continuous outcomes agreement.
All metric calculations will be logged. For each metric, both per-target and overall summaries can be recorded. For example, MLflow tracking might log Kt/V_R2, Kt/V_MAE, PET_R2, PET_MAE, etc., under the run’s metrics.
•	Calibration Assessment: Although Kt/V and PET are continuous, we want to ensure the model’s predicted values are not systematically biased. We will generate calibration curves or plots to visualize prediction vs. actual:
•	Sort or bin patients by predicted value (for each target), then compare the average predicted vs average actual in each bin. Ideally, points lie near the line y = x (indicating no bias).
•	For Kt/V, a specific calibration check might be how well the model predicts above vs below the adequacy threshold (1.7). We could compute the proportion of patients predicted adequate vs actually adequate to see if those align (this mimics a calibration curve if treating it as a classification at that threshold).
•	The evaluation step will produce a plot of predicted vs true values for each target, possibly with a LOESS fit or diagonal reference line to illustrate calibration. This plot will be saved (e.g. as PNG) and logged as an MLflow artifact for visual examination.
•	Model Comparison: If multiple models were trained (e.g. RF vs XGB), the evaluation will compare their performance on the test set. A simple table of metrics or a bar chart can be logged, and the better model for each metric identified. This comparative analysis will inform which model to carry forward for deployment. All comparisons should use the same test data to be fair.
•	Interpretability Aids: Though not explicitly requested, it’s beneficial to consider feature importance or SHAP value analysis on the best model. This can be a part of evaluation to ensure the model is making clinically plausible decisions. For instance, we expect PET prediction to heavily weight membrane transport indicators (like D/P creatinine ratio features if any), and Kt/V prediction to rely on treatment volume and residual renal function (urine output, etc.). The pipeline can log feature importance rankings as an artifact (CSV or plot).
The ZenML evaluation step will take the trained model(s) and test dataset as inputs. It will not perform any further training – just compute metrics and produce outputs. All results are logged via MLflow. By keeping the test set separate and only evaluating once, we ensure a true measure of generalization.
Pipeline Design & Configuration (ZenML + MLflow)
This project will be structured as a ZenML pipeline with modular steps, each responsible for a clear task as described above. The pipeline improves maintainability and reusability, following MLOps best practices:
•	Pipeline Steps:
•	Data Ingestion Step: Loads the Excel CRF, cleans data, outputs a DataFrame.
•	Split Step: Splits data into train/test, outputs two sets (train set goes to next steps, test set is held for final eval).
•	Preprocessing Step: Computes CCI, derives time features, scales/encodes data. Outputs processed train data (and the same transformers to apply on test in evaluation). Also saves preprocessing artifacts (e.g. scaler.h5).
•	Feature Engineering Step: Performs LASSO feature selection on the training set. Outputs a reduced feature set (train data with selected features). Optionally logs selected feature names.
•	Model Training Step(s): Trains one or more models on the processed training data. Could be a single step that trains all models, or multiple parallel steps (one per model type). Outputs trained model artifacts (and possibly validation scores).
•	Evaluation Step: Uses the saved model(s) to predict on the untouched test set. Computes metrics (MAE, MSE, R², ICC) and generates calibration plots. Outputs evaluation report/metrics.
Each step is self-contained and interacts via well-defined inputs/outputs (for example, the output of preprocessing is the input to feature engineering, etc.), enabling caching and independent debugging.
•	Step Configuration: ZenML allows configuring each step via parameters or configuration classes (could be provided in a YAML/JSON). We will define configs such as:
•	DataIngestionConfig (e.g. file path for Excel, sheet name).
•	SplitConfig (test split ratio, random seed).
•	PreprocessingConfig (e.g. scaling method = "standard" or "minmax", features to log-transform).
•	ModelConfig for each model (e.g. hyperparameters like n_estimators, max_depth for Random Forest; learning_rate for XGBoost).
•	EvaluationConfig (e.g. threshold for Kt/V adequacy if used for calibration, number of bins for calibration curve).
These configurations make the pipeline flexible: one can adjust settings without altering code, promoting easier experimentation.
•	Experiment Tracking (MLflow Integration): All steps will utilize MLflow for logging:
•	ZenML’s MLflow integration (@step(experiment_tracker="mlflow_tracker")) will be enabled on steps such as training and evaluation. This ensures that parameters and metrics inside those steps are automatically captured[12][13].
•	We will call mlflow.autolog() or explicit mlflow.log_param/metric within steps to record relevant information. For example, the training step logs model hyperparameters and training performance; the evaluation step logs final metrics.
•	Artifacts Logging: MLflow will also log important artifacts:
o	Preprocessing artifacts (scalers, encoders) – so that any run has a record of the exact transformer objects used.
o	Model files (serialized models) – enabling later retrieval or deployment via MLflow’s model registry.
o	Plots (calibration curve, feature importance charts) – for insight into model behavior.
•	Each pipeline run (or each step run) can be associated with an MLflow run under a designated experiment name (e.g. "DETECT_PD_Pipeline"). ZenML will link pipeline runs to MLflow runs for easy navigation[14].
•	By leveraging MLflow’s UI, we can compare runs visually, see how changes in preprocessing or hyperparameters affected metrics[15]. All metrics/parameters mentioned in Requirements are tracked, ensuring experiment reproducibility and auditability.
•	Versioning and Reproducibility: The combination of ZenML and MLflow means every pipeline run is versioned. Data splits (with fixed seed) are repeatable, and artifacts are stored (ZenML’s artifact store + MLflow artifact logging). This addresses the need to later serve the exact model that was evaluated, and to trace back which preprocessing was applied.
•	Example Pipeline Flow: In summary, a single pipeline run might be triggered via a Python script or CLI. The pipeline reads config files, executes each step in turn, and at completion, one can check MLflow to see: which features were selected, which model performed best, and the final metrics on test data. If a new experiment is needed (e.g. trying a different scaling or an additional feature), one updates the config and re-runs the pipeline, producing a new MLflow run for comparison.
Model Serving Interface (Future Work)
Though outside the immediate scope of model development, the PRD anticipates the need for a model serving solution to deliver predictions on new patient data. The pipeline should be designed to facilitate deployment: - The final trained model (or models) along with preprocessing transformers will be containerized. For example, using ZenML’s deployment capabilities or manual Docker setup, we can create an inference server (e.g. a FastAPI or Flask app) that loads the model and scaler objects. - Input: A user (e.g. clinician) would provide a new patient's data in the same format as the CRF (demographics, comorbidities, lab results, etc.). - Process: The service will apply the saved preprocessing pipeline (CCI calculation, feature scaling, etc.), then feed the data into the trained model. - Output: Predicted Kt/V and PET values, with optional interpretation (e.g. “predicted PET = 0.80, indicating average transporter” or “predicted Kt/V = 1.5, slightly below adequacy target”). The service might also return the confidence or prediction interval if available. - Architecture: The serving could be implemented as a Docker image containing the model and code. ZenML pipeline might eventually include a deployment step that takes the model artifact and pushes it to a model registry or directly builds an image.
For now, this interface is a placeholder – we ensure that everything needed for serving (model file, preprocessing artifacts, code to compute features) is saved and versioned. The Docker compatibility will be kept in mind (e.g. avoiding system-specific dependencies, using environment YAML/requirements for replication). In a future phase, a CI/CD pipeline can pick up the latest validated model from MLflow and deploy it to a cloud service or on-prem server for real-time use.
Conclusion
This PRD outlined a comprehensive ML pipeline to predict PD adequacy metrics Kt/V and PET using the DETECT-PD dataset. By structuring the solution into clear components – data ingestion, preprocessing (with CCI and time features), feature selection, model training, and evaluation – and leveraging ZenML for orchestration and MLflow for tracking, we ensure the development process is reproducible, well-documented, and aligned with MLOps best practices. The approach balances clinical insight (e.g. using Charlson Index and known time intervals) with modern ML techniques (LASSO feature selection, ensemble models), aiming to deliver a tool that can potentially streamline PD patient monitoring. All intermediate results and artifacts will be logged for transparency, and provisions are made for eventual deployment such that this predictive model can be accessed via a user-friendly interface in the future.
________________________________________
[1] [2] cdn.clinicaltrials.gov
https://cdn.clinicaltrials.gov/large-docs/27/NCT06842927/Prot_SAP_000.pdf
[3] [4] Peritoneal Dialysis and Adequacy - DaVita
http://www.davita.com/treatment-services/peritoneal-dialysis/peritoneal-dialysis-and-adequacy
[5] [6] The Peritoneal Equilibration Test for Peritoneal Dialysis - Home Dialysis Central
https://homedialysis.org/life-at-home/articles/the-peritoneal-equilibration-test-for-pd
[7] [8] [9] [10] Charlson Comorbidity Index - Wikipedia
https://en.wikipedia.org/wiki/Charlson_Comorbidity_Index
[11] Assessment of Regression Models Performance • performance
https://easystats.github.io/performance/
[12] [13] [14] [15] Integrate MLflow with ZenML - Experiment Tracker Integrations
https://www.zenml.io/integrations/mlflow
